{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## intro\n",
    "In the custom-task-tutorial notebook, we demonstrated how to create a Task that takes file-based data as an input to the Task code. But what if the user needs to pass in a parameter when they use the tool? This is where you would use a 'string' port versus a 'directory' port. This tutorial will demonstrate how to write the Task code to read input from a string port, how to register a Task with string ports, and an example of how the string port is used when calling the task with gbdxtools. \n",
    "\n",
    "For this tutorial, it will be helpful to have completed the custom-task-tutorial notebook first, as this tutorial will build off of it. We are going to take the Task that we wrote in that tutorial, which clips a raster to a shapefile, and add an additional functionality to it. We're going to add a parameter to the Task which allows the user to specify which portion of the raster will be removed, either the portion of the raster that falls outside the shapefile or the that which falls within the shapefile. For the sake of clarity, and a little brevity, we're going to call this the Doughnut Task, in which a user can select between doughnut and doughnut-hole for the clip selection. If 'doughnut' is specified in the call to this Task within a Workflow, then the inner portion of the raster will be removed, and the outer portion will be retained. If 'doughnut-hole' is specified, then the outer portion of the raster will be removed, and the inner portion retained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### string ports: aop task example\n",
    "In order to understand how string ports are handled in GBDX, let's review a common Task already on GBDX, the Advanced Image Preprocessor Task. This is the Task that orthorectifies the raw imagery that comes off of the satellites, and handles image preprocessing options such as atmospheric compensation and pan sharpening. \n",
    "\n",
    "To review, we call this Task in gbdxtools using its registered Task name, \"AOP_Strip_Processor\", and then set it's required inputs. This Task has only one required input, \"data\", which is the S3 URL of the raw image to be processed. \n",
    "\n",
    "```python\n",
    "source_s3 = 's3://receiving-dgcs-tdgplatform-com/056244928010_01_003'\n",
    "aop_task = gbdx.Task('AOP_Strip_Processor', data=source_s3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this Task only has one required input, it has several optional inputs that allow the user to specify exactly how the image should be processed ([documentation here](https://gbdxdocs.digitalglobe.com/docs/advanced-image-preprocessor)). The user can specify that the image be pan sharpened, have dynamic range adjustment applied, specify the projection for orthorectification, etc. \n",
    "\n",
    "Here's an example that explicitly specifies additional processing steps.\n",
    "\n",
    "```python\n",
    "aop_task = gbdx.Task('AOP_Strip_Processor', data=source_s3, enable_acomp=True, enable_pansharpen=False, enable_dra=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the types of data input here. For the input port '`data`', we're passing in a file-based type data - the raw image that is stored in the S3 directory we've specified. When the Task runs, the specified input data will be automatically mounted inside the Docker container, at `/mnt/work/input/data`.\n",
    "\n",
    "But for the parameters that are passed in via string ports, a ports.json file is automatically generated and mounted inside the Docker container, at `/mnt/work/input/ports.json`. The ports.json file contains the name/value pairs for each string port. Here's an example of the type of ports.json file that is automatically generated when our above AOP task is called. \n",
    "\n",
    "```json\n",
    "{\n",
    "\t\"enable_acomp\": true,\n",
    "\t\"enable_pansharpen\": false,\n",
    "\t\"enable_dra\": false\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### string ports: doughnut task example\n",
    "Now, let's take this concept and apply it to our example Doughnut Task. We've already discussed how the code needs to point to the `/mnt/work/input/<port name>` for its input data. Let's look at how we can point the Task code to parameter inputs read from the ports.json file. First, here's an example calling the Doughtnut Task in gbdxtools:\n",
    "\n",
    "```python\n",
    "source_s3 = 's3://receiving-dgcs-tdgplatform-com/056244928010_01_003'\n",
    "doughnut_task = gbdx.Task('doughnut_clip', data_in=source_s3, clip_selection='doughnut')\n",
    "```\n",
    "\n",
    "When this Task runs with the Workflow system, the input image will automatically be mounted at `/mnt/work/input/data_in`, and a ports.json file will be automatically generated and mounted at `/mnt/work/input/ports.json`. This is what the ports.json file will contain:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"clip_selection\":\"doughnut\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's modify the Task code to read its parameter input from the ports.json file. The first part of the Doughnut Task script will be the same as the Clip Raster Task script from the previous tutorial. \n",
    "\n",
    "> We need to import the raster and shapefile processing libraries, and pull the raster and shapefile from their associated input ports. \n",
    "\n",
    "```python\n",
    "# import libraries \n",
    "import fiona\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# set the input ports path\n",
    "in_path = '/mnt/work/input'\n",
    "shape_path = in_path + '/input_shapefile'\n",
    "raster_path = in_path + '/input_raster'\n",
    "\n",
    "# search the input shapefile port for the first shapefile that we specify in the call to this task\n",
    "my_shape = glob.glob1(shape_path, '*.shp')[0]\n",
    "\n",
    "# search the input image port for the first geotiff that we specify in the call to this task\n",
    "my_raster = glob.glob1(raster_path, '*.tif')[0]\n",
    "```\n",
    "\n",
    "> Next, we open the ports.json file and load its contents \n",
    "\n",
    "```python\n",
    "with open('/mnt/work/input/ports.json') as portsfile:\n",
    "    ports_js = json.load(portsfile)\n",
    "```\n",
    "\n",
    "> Assign the value from 'clip_selection' to the `crop_selection` variable\n",
    "\n",
    "```python\n",
    "cs = ports_js['clip_selection']\n",
    "```\n",
    "\n",
    "> Then we write some simple logic that sets the default clip parameters, which is what we want if the user select `doughnut_hole`, but then reverse the values if the user selects `doughnut`\n",
    "\n",
    "```python\n",
    "# set default clip parameters, reverse values if clip_selection is 'doughnut'\n",
    "invert_method = False\n",
    "crop_method = True\n",
    "\n",
    "if crop_select == 'doughnut':\n",
    "    invert_method = True\n",
    "    crop_method = False\n",
    "```\n",
    "\n",
    "> The following code is identical to our original Clip Task code, wherein we define the output port and its filepath and navigate to the output directory, then use the Fiona library to grab the geometery from the shapefile. \n",
    "\n",
    "```python\n",
    "# define the name of the output data port\n",
    "out_path = '/mnt/work/output/data_out'\n",
    "\n",
    "# create the output data port\n",
    "if os.path.exists(out_path) == False:\n",
    "  os.makedirs(out_path)\n",
    "\n",
    "# change directories to the output data port\n",
    "os.chdir(out_path)\n",
    "\n",
    "# open the input shapefile and get the polygon features for clipping\n",
    "with fiona.open(os.path.join(shape_path, my_shape), \"r\") as shapefile:\n",
    "  features = [feature[\"geometry\"] for feature in shapefile]\n",
    "```\n",
    "\n",
    "> This next code block is similar to the Clip Task code that uses the Rasterio library to clip the raster and copy its metadata, but we add the '`invert`' parameter and pass in the '`invert_method`' we defined above, which is `True` if the user specifies '`doughnut`' and `False` if they specify '`doughnut-hole`'. If `invert_method` is True, `crop` must be False.  \n",
    "\n",
    "```python\n",
    "# open the input image, clip the image with the shapefile and get the image metadata\n",
    "with rasterio.open(os.path.join(raster_path, my_raster)) as src:\n",
    "  out_raster, out_transform = rasterio.mask.mask(src, features, crop=crop_method, invert=invert_method)\n",
    "  out_meta = src.meta.copy()\n",
    "```\n",
    "\n",
    "> Finally, write out the metadata to the new raster, 'masked.tif', as we did before\n",
    "\n",
    "```python\n",
    "# write out the metadata to the raster\n",
    "out_meta.update({\"driver\": \"GTiff\",\n",
    "  \"height\": out_raster.shape[1],\n",
    "  \"width\": out_raster.shape[2],\n",
    "  \"transform\": out_transform})\n",
    "\n",
    "# write out the output raster\n",
    "with rasterio.open(\"masked.tif\", \"w\", **out_meta) as dest:\n",
    "  dest.write(out_raster)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Now that we understand a little more about how to use string ports, let's write and register the new Doughnut Task to the GBDX registery, following the same sequence of steps that we did in the Clip Task registeration tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inputs and outputs\n",
    "We've already covered the Doughnut Task code, in these next few steps we're just going to set up a directory, write and save the task code there. \n",
    "\n",
    "#### 1.1 Run the code in the following cell to create the 'doughnut_tutorial_files/docker_projects/bin' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists('doughnut_tutorial_files') == False:\n",
    "  os.makedirs('doughnut_tutorial_files/docker_projects/bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Run the code in the following cell to navigate to the directory you just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/elizabethgolden/Dropbox/DG/notebooks/doughnut_tutorial_files/docker_projects/bin\n"
     ]
    }
   ],
   "source": [
    "cd doughnut_tutorial_files/docker_projects/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Run the code in the following cell to write the code that we just reviewed to 'doughnut_task.py'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting doughnut_task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile doughnut_task.py\n",
    "\n",
    "# import libraries\n",
    "import fiona\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# set the input ports path\n",
    "in_path = '/mnt/work/input'\n",
    "shape_path = in_path + '/input_shapefile'\n",
    "raster_path = in_path + '/input_raster'\n",
    "\n",
    "# search the input shapefile port for the first shapefile that we specify in the call to this task\n",
    "my_shape = glob.glob1(shape_path, '*.shp')[0]\n",
    "\n",
    "# search the input image port for the first geotiff that we specify in the call to this task\n",
    "my_raster = glob.glob1(raster_path, '*.tif')[0]\n",
    "\n",
    "# open and load the contents of ports.json\n",
    "with open('/mnt/work/input/ports.json') as portsfile:\n",
    "    ports_js = json.load(portsfile)\n",
    "\n",
    "# assign the value from 'crop_selection'\n",
    "crop_select = ports_js['clip_selection']\n",
    "\n",
    "# set default clip parameters, reverse the values if clip_selection is 'doughnut'\n",
    "invert_method = False\n",
    "crop_method = True\n",
    "\n",
    "if crop_select == 'doughnut':\n",
    "    invert_method = True\n",
    "    crop_method = False\n",
    "\n",
    "# define the name of the output data port\n",
    "out_path = '/mnt/work/output/data_out'\n",
    "\n",
    "# create the output data port\n",
    "if os.path.exists(out_path) == False:\n",
    "  os.makedirs(out_path)\n",
    "\n",
    "# change directories to the output data port\n",
    "os.chdir(out_path)\n",
    "\n",
    "# open the input shapefile and get the polygon features for clipping\n",
    "with fiona.open(os.path.join(shape_path, my_shape), \"r\") as shapefile:\n",
    "  features = [feature[\"geometry\"] for feature in shapefile]\n",
    "\n",
    "# open the input image, clip the image with the shapefile and get the image metadata\n",
    "with rasterio.open(os.path.join(raster_path, my_raster)) as src:\n",
    "  out_raster, out_transform = rasterio.mask.mask(src, features, crop=crop_method, invert=invert_method)\n",
    "  out_meta = src.meta.copy()\n",
    "\n",
    "# write out the metadata to the raster\n",
    "out_meta.update({\"driver\": \"GTiff\",\n",
    "  \"height\": out_raster.shape[1],\n",
    "  \"width\": out_raster.shape[2],\n",
    "  \"transform\": out_transform})\n",
    "\n",
    "# write out the output raster\n",
    "with rasterio.open(\"masked.tif\", \"w\", **out_meta) as dest:\n",
    "  dest.write(out_raster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Dockerfile\n",
    "We're going to write a Dockerfile the same as before, only this time we're adding wrapping up the new Doughnut Task script. \n",
    "\n",
    "#### 2.1 Run the code in the following cell to navigate back one folder to /docker_projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/elizabethgolden/Dropbox/DG/notebooks/doughnut_tutorial_files/docker_projects\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Run the code in the following cell to write '`Dockerfile`', note that we're placing the new '`doughnut_task.py`' script here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM continuumio/miniconda\n",
    "\n",
    "RUN conda install rasterio\n",
    "RUN conda install fiona\n",
    "\n",
    "RUN mkdir /my_scripts\n",
    "ADD ./bin /my_scripts\n",
    "CMD python /my_scripts/doughnut_task.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Build your Docker\n",
    "Next, build the new Docker image as we did for the Clip Raster Task, but for the Doughnut Task. \n",
    "\n",
    "NOTE: AT THIS POINT IN THE TUTORIAL, WE'RE GOING TO LEAVE THE JUPYTER NOTEBOOK AND SWITCH TO DOCKER\n",
    "\n",
    "#### 3.1 Bring up a terminal window on your computer and start Docker.\n",
    "\n",
    "#### 3.2 Within the terminal window, navigate to the folder containing the Dockerfile, under 'doughnut_tutorial_files/docker_projects'.\n",
    "\n",
    "```\n",
    "cd <full/path/to>/doughnut_tutorial_files/docker_projects\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Copy and paste the following Docker command to build a Docker from your Dockerfile, but __FIRST REPLACE 'gbdxtrainer' WITH YOUR DOCKER USERNAME__.  \n",
    "\n",
    "```\n",
    "docker build -t gbdxtrainer/doughnut_docker .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Push your Docker to Docker Hub\n",
    "\n",
    "#### 4.1 While still within the terminal window, log in to Docker Hub using the following Docker command USING YOUR DOCKER HUB LOGIN CREDENTIALS. \n",
    "```\n",
    "docker login --username gbdxtrainer --password a_fake_password\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Once logged in, use the following Docker command to push your Docker image to Docker Hub, CHANGE TO YOUR DOCKER USERNAME. Note: this may a few minutes.\n",
    "```\n",
    "docker push gbdxtrainer/doughnut_docker\n",
    "```\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Add GBDX collaborators to your Docker Hub repository\n",
    "Your Docker repository on Docker Hub can be public or private, but certain GBDX collaborators must be added to the repository in order for the Platform to pull and run the Docker. \n",
    "\n",
    "#### 5.1 Log in to Docker Hub https://hub.docker.com/\n",
    "\n",
    "You should now see the Docker image that you just pushed to Docker Hub, in it's own repository of the same name. \n",
    "\n",
    "#### 5.2 Open the repository and select the 'Collaborators' tab. Under 'Username', enter each of the following as Collaborators to your repository. This is what will allow GBDX to pull and execute your Task.  \n",
    "```\n",
    "tdgpbuild\n",
    "tdgpdeploy\n",
    "tdgplatform\n",
    "```\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Task definitition \n",
    "NOTE: WE'RE BACK TO THE JUPYTER NOTEBOOK FOR THE REST OF THE TUTORIAL\n",
    "\n",
    "We are going to write a Task definition schema as we did before, only add the new string input port, as shown here. Note that the 'type' for this input port is 'string', not 'directory'. \n",
    "\n",
    "```json\n",
    "{\n",
    "        \"required\": true,\n",
    "        \"description\": \"The part of raster to retain when clipped, options are 'doughnut' or 'doughnut-hole'.\",\n",
    "        \"name\": \"clip_selection\",\n",
    "        \"type\": \"string\"\n",
    "    }\n",
    "```\n",
    "\n",
    "#### 6.1 Run the code in the following cell to navigate back one directory (back out of the '`/docker_projects`' directory to the '`/task_tutorial_files`' directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/elizabethgolden/Dropbox/DG/notebooks/doughnut_tutorial_files\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 MODIFY THE DOCKER IMAGE AND TASK NAME WITH YOURS, then run the code in the following cell to write the full JSON document that we just reviewed to doughnut-task-definition.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting doughnut-task-definition.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile doughnut-task-definition.json\n",
    "{\n",
    "    \"inputPortDescriptors\": [{\n",
    "        \"required\": true,\n",
    "        \"description\": \"Directory containing a raster.\",\n",
    "        \"name\": \"input_raster\",\n",
    "        \"type\": \"directory\"\n",
    "    }, {\n",
    "        \"required\": true,\n",
    "        \"description\": \"Directory containing a shapefile\",\n",
    "        \"name\": \"input_shapefile\",\n",
    "        \"type\": \"directory\"\n",
    "    }, {\n",
    "        \"required\": true,\n",
    "        \"description\": \"Which part of raster to retain when clipped. Options are 'doughnut' and 'doughnut-hole'.\",\n",
    "        \"name\": \"clip_selection\",\n",
    "        \"type\": \"string\"\n",
    "    }],\n",
    "    \"outputPortDescriptors\": [{\n",
    "        \"required\": true,\n",
    "        \"description\": \"A cropped tif.\",\n",
    "        \"name\": \"data_out\",\n",
    "        \"type\": \"directory\"\n",
    "    }],\n",
    "    \"containerDescriptors\": [{\n",
    "        \"type\": \"DOCKER\",\n",
    "        \"command\": \"\",\n",
    "        \"properties\": {\n",
    "            \"image\": \"gbdxtrainer/doughnut_docker:latest\"\n",
    "        }\n",
    "    }],\n",
    "    \"description\": \"Clips a raster to shapefile, clip selection can be inverted.\",\n",
    "    \"name\": \"doughnut_clip_gt\",\n",
    "    \"version\": \"1.0.3\",\n",
    "    \"properties\": {\n",
    "        \"isPublic\": false,\n",
    "        \"timeout\": 36000\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 7. Register Task\n",
    "All of the pieces are in place to register the new Doughnut Task to the Platform using gbdxtools.   \n",
    "\n",
    "#### 7.1 Fill in your your GBDX username, password, client ID and client secret in the following cell. This information can be found under your Profile information at https://gbdx.geobigdata.io/profile. If you have a GBDX config file, you can uncomment and use the first two lines of code to authenticate into GBDX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from gbdxtools import Interface\n",
    "# gbdx = Interface()\n",
    "\n",
    "import gbdxtools\n",
    "gbdx = gbdxtools.Interface(\n",
    "    username='',\n",
    "    password='',\n",
    "    client_id='',\n",
    "    client_secret='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Run the code in the following cell to submit your Task to the Task registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'doughnut_clip_gt:1.0.3 has been submitted for registration.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdx.task_registry.register(json_filename = 'doughnut-task-definition.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 Wait a few minutes, then see if the Task registration has completed by runing the code in the following cell to create an instance of your Task. FIRST REPLACE 'gt' IN THE TASK NAME WITH YOUR INITIALS.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doughnut_task = gbdx.Task(\"doughnut_clip_gt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 8. Workflow\n",
    "The last step is to test the Doughnut Task in a Workflow with gbdxtools. This Workflow is identical to the Clip Task Workflow from before, but using the doughnut task registered name and clip selection parameter. \n",
    "\n",
    "#### 8.1 Run the code in the following cell to execute a Workflow using the new Doughnut Task. FIRST REPLACE 'gt' IN THE TASK NAME WITH YOUR INITIALS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4629530075806175553\n"
     ]
    }
   ],
   "source": [
    "# define the S3 path for an image by passing in its Catalog ID \n",
    "source_s3 = gbdx.catalog.get_data_location(catalog_id='10400100245B7800')\n",
    "\n",
    "# define an input shapefile from S3\n",
    "shape_path = 's3://tutorial-files/this_shp_will_clip_10400100245B7800/'\n",
    "\n",
    "# define the 'AOP_Strip_Processor' \n",
    "aop_task = gbdx.Task('AOP_Strip_Processor', data=source_s3, enable_pansharpen=True)\n",
    "\n",
    "# define the 'gdal_cli' Task\n",
    "glue_task = gbdx.Task('gdal-cli', data=aop_task.outputs.data.value, execution_strategy='runonce',\n",
    "                         command=\"\"\"mv $indir/*/*.tif $outdir/\"\"\")\n",
    "\n",
    "# define the 'clip_raster' Task \n",
    "doughnut_task = gbdx.Task(\"doughnut_clip_gt\", input_raster=glue_task.outputs.data.value, input_shapefile=shape_path, clip_selection=\"doughnut\")\n",
    "\n",
    "# build a Workflow to run the 'clip_raster' Task\n",
    "workflow = gbdx.Workflow([aop_task, glue_task, doughnut_task])\n",
    "\n",
    "# specify where to save the output within your customer bucket\n",
    "workflow.savedata(doughnut_task.outputs.data_out, location='task_demo/doughnut')\n",
    "\n",
    "# kick off the Workflow and keep track of the Workflow ID\n",
    "workflow.execute()\n",
    "print workflow.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBDX is now running your Workflow. While the Workflow is running, you can interact with the Workflow object and track its status. \n",
    "\n",
    "#### 8.2 Run the code in the following cell to get the status of the Workflow. This call will return the the status of whatever event is currently underway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'event': u'succeeded', u'state': u'complete'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your Workflow has completed (and succeeded!), you will be able to see the output in your customer S3 bucket.\n",
    "\n",
    "NOTE: AT THIS POINT IN THE TUTORIAL, WE'RE GOING TO LEAVE THE JUPYTER NOTEBOOK AND SWITCH TO THE S3 BROWSER \n",
    "\n",
    "#### 8.3  Log into the S3 browser [http://s3browser.geobigdata.io](http://s3browser.geobigdata.io/login.html) using your GBDX credentials. \n",
    "\n",
    "#### 8.4 Navigate to 'task_demo/doughnut' to find the saved output of your Workflow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
